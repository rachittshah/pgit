<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Evaluation Dashboard</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body class="bg-gray-50 min-h-screen">
    <div class="min-h-screen flex items-center justify-center">
        <div class="max-w-md w-full bg-white rounded-lg shadow-lg p-8 text-center">
            <div class="mb-6">
                <i class="fas fa-chart-line text-6xl text-gray-400 mb-4"></i>
                <h1 class="text-2xl font-bold text-gray-900 mb-2">No Results Available</h1>
                <p class="text-gray-600">
                    Run an evaluation first to see results in the dashboard.
                </p>
            </div>

            <div class="bg-gray-50 rounded-lg p-4 text-left text-sm font-mono text-gray-700 mb-6">
                <div class="mb-2"># Run an evaluation:</div>
                <div class="text-blue-600">llm-eval eval</div>
                <div class="mt-2 mb-2"># Then view results:</div>
                <div class="text-blue-600">llm-eval view</div>
            </div>

            <div class="space-y-2 text-sm text-gray-600">
                <p><strong>Quick Start:</strong></p>
                <p>1. Create a configuration file (llmeval.yaml)</p>
                <p>2. Set your API keys for desired providers</p>
                <p>3. Run evaluations with <code class="bg-gray-100 px-2 py-1 rounded">llm-eval eval</code></p>
                <p>4. View results with <code class="bg-gray-100 px-2 py-1 rounded">llm-eval view</code></p>
            </div>

            <div class="mt-6 pt-6 border-t border-gray-200">
                <p class="text-xs text-gray-500">
                    LLM Evaluation Framework v0.1.0
                </p>
            </div>
        </div>
    </div>
</body>
</html>